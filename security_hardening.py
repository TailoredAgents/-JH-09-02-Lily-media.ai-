#!/usr/bin/env python3
"""
Security Hardening Script for Lily AI Social Media Platform
Enforces strong secrets and validates security configuration
"""

import os
import secrets
import string
import sys
from pathlib import Path
from dotenv import load_dotenv
from backend.core.env_validator import validate_environment

# Load .env file if it exists
if os.path.exists('.env'):
    load_dotenv('.env')

def generate_strong_secret(length: int = 64) -> str:
    """Generate a cryptographically strong secret key"""
    # Use only alphanumeric and safe special characters for .env compatibility
    alphabet = string.ascii_letters + string.digits + "_-+"
    return ''.join(secrets.choice(alphabet) for _ in range(length))

def generate_token_encryption_key() -> str:
    """Generate a 32-character token encryption key"""
    # Use only alphanumeric for better compatibility
    alphabet = string.ascii_letters + string.digits
    return ''.join(secrets.choice(alphabet) for _ in range(32))

def check_weak_secrets() -> list:
    """Check for weak or default secrets"""
    weak_secrets = []
    
    # Check SECRET_KEY
    secret_key = os.getenv("SECRET_KEY", "")
    if not secret_key:
        weak_secrets.append("SECRET_KEY is not set")
    elif len(secret_key) < 32:
        weak_secrets.append("SECRET_KEY is too short (minimum 32 characters)")
    elif secret_key in ["your-super-secret-key-change-this", "dev-secret-key", "secret"]:
        weak_secrets.append("SECRET_KEY is using a default/weak value")
    
    # Check TOKEN_ENCRYPTION_KEY
    token_key = os.getenv("TOKEN_ENCRYPTION_KEY", "")
    if not token_key:
        weak_secrets.append("TOKEN_ENCRYPTION_KEY is not set")
    elif len(token_key) < 32:
        weak_secrets.append("TOKEN_ENCRYPTION_KEY is too short (minimum 32 characters)")
    elif token_key == "your-secure-32-char-encryption-key-here":
        weak_secrets.append("TOKEN_ENCRYPTION_KEY is using the default example value")
    
    return weak_secrets

def create_secure_env_file():
    """Create a .env file with strong secrets"""
    env_file = Path(".env")
    
    print("🔒 GENERATING SECURE ENVIRONMENT CONFIGURATION")
    print("=" * 60)
    
    # Generate strong secrets
    strong_secret = generate_strong_secret(64)
    token_encryption_key = generate_token_encryption_key()
    
    env_content = f"""# Lily AI Social Media - Secure Environment Configuration
# Generated by security_hardening.py

# Core Security
SECRET_KEY={strong_secret}
TOKEN_ENCRYPTION_KEY={token_encryption_key}

# Environment
ENVIRONMENT=development

# Database (Update with your PostgreSQL connection)
DATABASE_URL=postgresql://username:password@localhost/lily_media_ai

# AI Services
OPENAI_API_KEY=sk-your-openai-api-key-here

# Security Headers (recommended for production)
SECURE_HEADERS=true
SECURE_COOKIES=true
FORCE_HTTPS=false  # Set to true in production

# CORS Configuration
CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# Optional Services
REDIS_URL=redis://localhost:6379/0
SENTRY_DSN=your-sentry-dsn-here
SERPER_API_KEY=your-serper-api-key

# Social Platform API Keys (Optional)
TWITTER_API_KEY=your-twitter-api-key
TWITTER_API_SECRET=your-twitter-api-secret
INSTAGRAM_CLIENT_ID=your-instagram-client-id
INSTAGRAM_CLIENT_SECRET=your-instagram-client-secret
FACEBOOK_APP_ID=your-facebook-app-id
FACEBOOK_APP_SECRET=your-facebook-app-secret
LINKEDIN_CLIENT_ID=your-linkedin-client-id
LINKEDIN_CLIENT_SECRET=your-linkedin-client-secret

# Logging
LOG_LEVEL=INFO
"""
    
    if env_file.exists():
        backup_file = env_file.with_suffix('.env.backup')
        env_file.rename(backup_file)
        print(f"📁 Existing .env backed up to {backup_file}")
    
    env_file.write_text(env_content)
    print(f"✅ Created secure .env file with strong secrets")
    print(f"🔐 Generated SECRET_KEY: {len(strong_secret)} characters")
    print(f"🔐 Generated TOKEN_ENCRYPTION_KEY: {len(token_encryption_key)} characters")
    
    return env_file

def run_security_audit():
    """Run comprehensive security audit"""
    print("🛡️  SECURITY AUDIT REPORT")
    print("=" * 60)
    
    # Run environment validation
    validation_result = validate_environment()
    
    # Check weak secrets
    weak_secrets = check_weak_secrets()
    
    # Security status
    env = validation_result.get("environment", "unknown")
    validation_passed = validation_result.get("validation_passed", False)
    
    print(f"Environment: {env}")
    print(f"Validation Status: {'✅ PASSED' if validation_passed else '❌ FAILED'}")
    print(f"Configuration: {validation_result.get('configuration_completeness', 0)}% complete")
    print()
    
    # Critical security issues
    if validation_result.get("errors"):
        print("🚨 CRITICAL SECURITY ISSUES:")
        for error in validation_result["errors"]:
            print(f"  • {error}")
        print()
    
    # Weak secrets check
    if weak_secrets:
        print("🔓 WEAK SECRETS DETECTED:")
        for weak in weak_secrets:
            print(f"  • {weak}")
        print()
    
    # Security warnings
    if validation_result.get("warnings"):
        print("⚠️  SECURITY WARNINGS:")
        for warning in validation_result["warnings"]:
            print(f"  • {warning}")
        print()
    
    # Recommendations
    if validation_result.get("recommendations"):
        print("💡 SECURITY RECOMMENDATIONS:")
        for rec in validation_result["recommendations"]:
            print(f"  • {rec}")
        print()
    
    # Security score calculation
    total_issues = len(validation_result.get("errors", [])) + len(weak_secrets)
    security_score = max(0, 100 - (total_issues * 20))
    
    print("📊 SECURITY SCORE:")
    if security_score >= 80:
        print(f"  🟢 {security_score}/100 - GOOD")
    elif security_score >= 60:
        print(f"  🟡 {security_score}/100 - NEEDS IMPROVEMENT")
    else:
        print(f"  🔴 {security_score}/100 - CRITICAL ISSUES")
    
    return security_score, total_issues

def main():
    """Main security hardening function"""
    print("🔒 LILY AI SOCIAL MEDIA - SECURITY HARDENING")
    print("=" * 60)
    print()
    
    if len(sys.argv) > 1 and sys.argv[1] == "--generate-env":
        create_secure_env_file()
        print()
        print("⚠️  IMPORTANT: Update the generated .env file with your actual API keys and database credentials")
        return
    
    # Run security audit
    score, issues = run_security_audit()
    
    if issues > 0:
        print()
        print("🔧 SECURITY HARDENING ACTIONS:")
        print("  1. Run: python security_hardening.py --generate-env")
        print("  2. Update .env with your actual API keys and credentials")
        print("  3. Run security audit again to verify fixes")
        print()
        sys.exit(1)
    else:
        print("✅ Security hardening complete - no critical issues found")

if __name__ == "__main__":
    main()